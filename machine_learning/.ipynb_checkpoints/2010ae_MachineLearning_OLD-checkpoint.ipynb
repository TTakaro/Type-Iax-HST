{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalog = np.loadtxt(\"/Users/tktakaro/Documents/Type1ax_HST/curtis_files/sn2010ae/sn2010ae.phot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asci = open(\"/Users/tktakaro/Documents/Type1ax_HST/machine_learning/sn2010ae_set.reg\", \"r+\")\n",
    "\n",
    "def mysplit(s, delim=None):\n",
    "    return [x for x in s.split(delim) if x]\n",
    "\n",
    "text = asci.readlines()\n",
    "regionX = np.zeros(871)\n",
    "regionY = np.zeros(871)\n",
    "key = []\n",
    "for i in range(871):\n",
    "    A = mysplit(text[i+3], ' # ')\n",
    "    regionX[i] = mysplit(mysplit(A[0], 'point')[0],',')[0][1:]\n",
    "    regionY[i] = mysplit(mysplit(A[0], 'point')[0],',')[1][:-1]\n",
    "    if A[1][-3] == 'l':\n",
    "        key.append('green')\n",
    "    elif A[1][-3] == 'u':\n",
    "        key.append('blue')\n",
    "    else:\n",
    "        print(\"Error: neither blue nor green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a array with a space for each object in the catalog, to contain only X,Y positions\n",
    "positions = np.zeros([np.shape(catalog)[0], 2])\n",
    "allinfo = np.zeros(np.shape(catalog))\n",
    "\n",
    "j = 0 # Iteration variable for positions array\n",
    "for i in range(catalog.shape[0]): # Cycles through each object in catalog\n",
    "    # Checks for a S/N ratio of 50 or greater (to be lowered later)\n",
    "    if ((catalog[i][5] >= 50)&(abs(catalog[i][6]) < .25)&(abs(catalog[i][7]) < 1)\n",
    "        &(catalog[i][9] < .1)&(catalog[i][10] == 1)):\n",
    "        positions[j][0] = catalog[i][2] # Assigns X position with offset\n",
    "        positions[j][1] = catalog[i][3] # Assigns Y position with offset\n",
    "        allinfo[j] = catalog[i]\n",
    "        j = j + 1\n",
    "\n",
    "# Trims all zeros from end of positions array, left from objects with low S/N\n",
    "pos = positions[~np.all(positions == 0, axis=1)]\n",
    "info = allinfo[~np.all(allinfo == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolor1 = np.zeros(info.shape[0])\\ncolor2 = np.zeros(info.shape[0])\\ncolor3 = np.zeros(info.shape[0])\\ncolor4 = np.zeros(info.shape[0])\\ncolor5 = np.zeros(info.shape[0])\\ncolor6 = np.zeros(info.shape[0])\\nfor i in range(info.shape[0]):\\n    color1[i] = info[i][50] - info[i][37]\\n    color2[i] = info[i][50] - info[i][24]\\n    color3[i] = info[i][50] - info[i][11]\\n    color4[i] = info[i][37] - info[i][24]\\n    color5[i] = info[i][37] - info[i][11]\\n    color6[i] = info[i][24] - info[i][11]   \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding in colors (Deprecated)\n",
    "# F435W counts: 11, F555W counts: 24, F625W counts: 37, F814W counts: 50\n",
    "\"\"\"\n",
    "color1 = np.zeros(info.shape[0])\n",
    "color2 = np.zeros(info.shape[0])\n",
    "color3 = np.zeros(info.shape[0])\n",
    "color4 = np.zeros(info.shape[0])\n",
    "color5 = np.zeros(info.shape[0])\n",
    "color6 = np.zeros(info.shape[0])\n",
    "for i in range(info.shape[0]):\n",
    "    color1[i] = info[i][50] - info[i][37]\n",
    "    color2[i] = info[i][50] - info[i][24]\n",
    "    color3[i] = info[i][50] - info[i][11]\n",
    "    color4[i] = info[i][37] - info[i][24]\n",
    "    color5[i] = info[i][37] - info[i][11]\n",
    "    color6[i] = info[i][24] - info[i][11]   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "(871, 2)\n",
      "(871, 271)\n"
     ]
    }
   ],
   "source": [
    "for i in range(pos.shape[0]):\n",
    "    if (pos[i][0] > 3200) & (pos[i][0] < 3300) & (pos[i][1] > 800) & (pos[i][1] < 900):\n",
    "        print(i)\n",
    "\n",
    "pos[317] = np.zeros(2)\n",
    "info[317] = np.zeros(271)\n",
    "pos = pos[~np.all(pos == 0, axis=1)]\n",
    "info = info[~np.all(info == 0, axis=1)]\n",
    "print(pos.shape)\n",
    "print(info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pandas.DataFrame(info)\n",
    "#dataset[271] = color1\n",
    "#dataset[272] = color2\n",
    "#dataset[273] = color3\n",
    "#dataset[274] = color4\n",
    "#dataset[275] = color5\n",
    "#dataset[276] = color6\n",
    "dataset[271] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:271]\n",
    "Y = array[:,271]\n",
    "validation_size = 0.20\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "42\n",
      "379\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "flat = X.flatten()\n",
    "for i in range(flat.size):\n",
    "    if (np.isnan(flat[i])) or (not np.isfinite(flat[i])):\n",
    "        print(i//271)\n",
    "        print(i%271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replaces values which were previously NaN\n",
    "X[379][224] = 99.999\n",
    "X[379][42] = 99.999\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,\n",
    "                                                    test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.872381 (0.053657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.832029 (0.036207)\n",
      "KNN: 0.902422 (0.027452)\n",
      "CART: 0.867640 (0.047291)\n",
      "NB: 0.846439 (0.058901)\n",
      "SVM: 0.817847 (0.072044)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAESCAYAAAAG+ZUXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmWXIwd3MLEP/H9qWU9dXjCmWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e0b6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914285714286\n",
      "[[  7  13]\n",
      " [  2 153]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       blue       0.78      0.35      0.48        20\n",
      "      green       0.92      0.99      0.95       155\n",
      "\n",
      "avg / total       0.91      0.91      0.90       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now apply algorithm to catalog at large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111397\n",
      "111423\n",
      "111436\n",
      "111488\n",
      "111592\n",
      "111644\n",
      "187845\n",
      "188040\n",
      "190826\n",
      "191021\n",
      "203563\n",
      "203745\n",
      "207873\n",
      "207899\n",
      "207912\n",
      "207925\n",
      "208029\n",
      "208081\n",
      "216300\n",
      "216495\n",
      "231179\n",
      "231205\n",
      "231218\n",
      "231231\n",
      "231335\n",
      "231387\n",
      "241232\n",
      "241427\n",
      "255053\n",
      "255248\n",
      "256137\n",
      "256358\n",
      "302723\n",
      "302749\n",
      "302762\n",
      "302814\n",
      "302918\n",
      "302970\n",
      "303291\n",
      "303512\n",
      "304620\n",
      "304646\n",
      "304659\n",
      "304685\n",
      "304789\n",
      "304841\n",
      "318467\n",
      "318688\n",
      "342586\n",
      "342781\n",
      "440688\n",
      "440883\n",
      "460742\n",
      "460924\n",
      "466975\n",
      "467196\n",
      "489468\n",
      "489650\n",
      "494346\n",
      "494541\n",
      "496759\n",
      "496785\n",
      "496798\n",
      "496811\n",
      "496915\n",
      "496967\n",
      "509251\n",
      "509433\n",
      "517110\n",
      "517331\n",
      "537164\n",
      "537346\n",
      "570226\n",
      "570421\n",
      "588654\n",
      "588875\n",
      "593532\n",
      "593740\n",
      "594616\n",
      "594798\n",
      "606811\n",
      "607019\n",
      "609250\n",
      "609445\n",
      "634724\n",
      "634906\n",
      "637705\n",
      "637913\n",
      "637950\n",
      "637976\n",
      "637989\n",
      "638028\n",
      "638132\n",
      "638184\n",
      "639060\n",
      "639242\n",
      "639268\n",
      "655565\n",
      "655591\n",
      "655604\n",
      "655656\n",
      "655760\n",
      "655812\n",
      "655862\n",
      "656057\n",
      "659656\n",
      "659838\n",
      "664263\n",
      "664445\n",
      "679955\n",
      "679981\n",
      "679994\n",
      "680007\n",
      "680033\n",
      "680111\n",
      "680137\n",
      "680163\n",
      "680189\n",
      "685130\n",
      "685338\n",
      "692718\n",
      "692913\n",
      "692989\n",
      "693210\n",
      "700577\n",
      "700759\n",
      "704100\n",
      "704321\n",
      "714127\n",
      "714309\n",
      "727109\n",
      "727135\n",
      "727148\n",
      "727200\n",
      "727304\n",
      "727356\n",
      "729277\n",
      "729303\n",
      "729316\n",
      "729342\n",
      "729368\n",
      "729446\n",
      "729498\n",
      "729524\n",
      "733097\n",
      "733318\n",
      "752067\n",
      "752262\n",
      "757487\n",
      "757669\n",
      "774018\n",
      "774239\n",
      "777270\n",
      "777465\n",
      "802202\n",
      "802423\n",
      "811145\n",
      "811340\n",
      "830386\n",
      "830568\n",
      "837432\n",
      "837614\n",
      "843123\n",
      "843305\n",
      "843331\n",
      "857486\n",
      "857707\n",
      "873475\n",
      "873657\n",
      "881334\n",
      "881555\n",
      "886728\n",
      "886754\n",
      "886767\n",
      "886793\n",
      "886897\n",
      "886949\n",
      "890277\n",
      "890498\n",
      "896755\n",
      "896781\n",
      "896794\n",
      "896807\n",
      "896911\n",
      "896963\n",
      "926320\n",
      "926515\n",
      "928217\n",
      "928425\n",
      "974016\n",
      "974224\n",
      "975345\n",
      "975371\n",
      "975384\n",
      "975410\n",
      "975514\n",
      "975566\n",
      "985940\n",
      "986135\n",
      "990818\n",
      "991013\n",
      "1004910\n",
      "1005131\n",
      "1007865\n",
      "1007891\n",
      "1007904\n",
      "1007917\n",
      "1007943\n",
      "1008021\n",
      "1008073\n",
      "1008099\n",
      "1012743\n",
      "1012769\n",
      "1012782\n",
      "1012808\n",
      "1012912\n",
      "1012964\n",
      "1015750\n",
      "1015945\n",
      "1019273\n",
      "1019455\n",
      "1019481\n",
      "1020899\n",
      "1021107\n",
      "1036888\n",
      "1037070\n",
      "1042011\n",
      "1042037\n",
      "1042050\n",
      "1042102\n",
      "1042206\n",
      "1042258\n",
      "1045560\n",
      "1045781\n",
      "1050980\n",
      "1051188\n",
      "1061820\n",
      "1062015\n",
      "1097592\n",
      "1097787\n",
      "1097813\n",
      "1102741\n",
      "1102962\n",
      "1104909\n",
      "1105104\n",
      "1117917\n",
      "1118125\n",
      "1131983\n",
      "1132009\n",
      "1132022\n",
      "1132048\n",
      "1132152\n",
      "1132204\n",
      "1162903\n",
      "1163111\n",
      "1180789\n",
      "1180997\n",
      "1195152\n",
      "1195373\n",
      "1229840\n",
      "1230061\n",
      "1230924\n",
      "1231106\n",
      "1236615\n",
      "1236836\n",
      "1243390\n",
      "1243572\n",
      "1300274\n",
      "1300300\n",
      "1300313\n",
      "1300339\n",
      "1300365\n",
      "1300443\n",
      "1300521\n",
      "1356939\n",
      "1357160\n",
      "1378890\n",
      "1379072\n",
      "1391898\n",
      "1392093\n",
      "1400299\n",
      "1400481\n",
      "1406803\n",
      "1407011\n",
      "1444717\n",
      "1444743\n",
      "1444756\n",
      "1444782\n",
      "1444808\n",
      "1444886\n",
      "1444912\n",
      "1444938\n",
      "1444964\n",
      "1450434\n",
      "1450616\n",
      "1450642\n",
      "1452873\n",
      "1453081\n",
      "1469946\n",
      "1470128\n",
      "1500840\n",
      "1501061\n",
      "1510841\n",
      "1510867\n",
      "1510880\n",
      "1510893\n",
      "1510919\n",
      "1511023\n",
      "1511049\n",
      "1518997\n",
      "1519192\n",
      "1519218\n",
      "1527669\n",
      "1527864\n",
      "1527890\n",
      "1553956\n",
      "1554138\n",
      "1581327\n",
      "1581548\n",
      "1602194\n",
      "1602376\n",
      "1610324\n",
      "1610506\n",
      "1652871\n",
      "1653066\n",
      "1665879\n",
      "1666074\n",
      "1729564\n",
      "1729772\n",
      "1730106\n",
      "1730301\n",
      "1744985\n",
      "1745011\n",
      "1745024\n",
      "1745076\n",
      "1745180\n",
      "1745232\n",
      "1785635\n",
      "1785661\n",
      "1785674\n",
      "1785687\n",
      "1785791\n",
      "1785843\n",
      "1826827\n",
      "1826853\n",
      "1826866\n",
      "1826879\n",
      "1826905\n",
      "1826983\n",
      "1827009\n",
      "1827061\n",
      "1881324\n",
      "1881532\n",
      "1894061\n",
      "1894243\n",
      "1894269\n",
      "1920348\n",
      "1920543\n",
      "1922787\n",
      "1922982\n",
      "1925768\n",
      "1925963\n",
      "1959617\n",
      "1959643\n",
      "1959656\n",
      "1959669\n",
      "1959695\n",
      "1959773\n",
      "1959799\n",
      "1959825\n",
      "1959851\n",
      "1965063\n",
      "1965245\n",
      "1985930\n",
      "1986138\n",
      "2013030\n",
      "2013225\n",
      "2148801\n",
      "2149022\n",
      "2196742\n",
      "2196768\n",
      "2196781\n",
      "2196807\n",
      "2196911\n",
      "2196963\n",
      "2341753\n",
      "2341935\n",
      "2392701\n",
      "2392896\n",
      "2441481\n",
      "2441702\n",
      "2471020\n",
      "2471241\n",
      "2476982\n",
      "2477177\n",
      "2481860\n",
      "2482055\n",
      "2530098\n",
      "2530280\n",
      "2590531\n",
      "2590713\n",
      "2590739\n",
      "2645544\n",
      "2645765\n",
      "2941476\n",
      "2941658\n",
      "3038739\n",
      "3038765\n",
      "3038778\n",
      "3038830\n",
      "3038934\n",
      "3038986\n",
      "3047140\n",
      "3047166\n",
      "3047179\n",
      "3047205\n",
      "3047231\n",
      "3047335\n",
      "3047361\n",
      "3047387\n",
      "3068846\n",
      "3069054\n",
      "3083209\n",
      "3083391\n",
      "3133886\n",
      "3134094\n",
      "3149875\n",
      "3150096\n",
      "3162612\n",
      "3162794\n",
      "3162820\n",
      "3320063\n",
      "3320245\n",
      "3321147\n",
      "3321342\n",
      "3575616\n",
      "3575811\n",
      "3609491\n",
      "3609673\n",
      "3630087\n",
      "3630295\n",
      "3800004\n",
      "3800186\n",
      "3915992\n",
      "3916174\n",
      "3959081\n",
      "3959263\n",
      "4068565\n",
      "4068760\n",
      "4068786\n",
      "4192683\n",
      "4192865\n",
      "4368562\n",
      "4368783\n",
      "4543086\n",
      "4543268\n",
      "4543294\n",
      "4712164\n",
      "4712190\n",
      "4712203\n",
      "4712216\n",
      "4712242\n",
      "4712320\n",
      "4712346\n",
      "4712372\n",
      "4728450\n",
      "4728645\n",
      "4794574\n",
      "4794756\n",
      "4794782\n",
      "4876687\n",
      "4876882\n",
      "4876908\n",
      "4895657\n",
      "4895852\n",
      "5025711\n",
      "5025737\n",
      "5025750\n",
      "5025763\n",
      "5025789\n",
      "5025867\n",
      "5025919\n",
      "5082918\n",
      "5083126\n",
      "5446032\n",
      "5446058\n",
      "5446071\n",
      "5446123\n",
      "5446227\n",
      "5446279\n",
      "5612181\n",
      "5612402\n",
      "5715161\n",
      "5715382\n",
      "5745513\n",
      "5745734\n",
      "5881826\n",
      "5882021\n",
      "5882047\n",
      "6383447\n",
      "6383629\n",
      "6595072\n",
      "6595098\n",
      "6595111\n",
      "6595124\n",
      "6595228\n",
      "6595306\n",
      "6595640\n",
      "6595822\n",
      "6595848\n",
      "6849296\n",
      "6849517\n",
      "6879106\n",
      "6879288\n",
      "6879314\n",
      "7115392\n",
      "7115418\n",
      "7115431\n",
      "7115444\n",
      "7115470\n",
      "7115574\n",
      "7115600\n",
      "7115626\n",
      "7524628\n",
      "7524823\n",
      "7854706\n",
      "7854927\n",
      "8362289\n",
      "8362497\n",
      "8369335\n",
      "8369530\n",
      "8688302\n",
      "8688510\n",
      "8908354\n",
      "8908549\n",
      "8908575\n",
      "9089924\n",
      "9090132\n",
      "9676368\n",
      "9676589\n",
      "9899943\n",
      "9900138\n",
      "9900164\n",
      "9981243\n",
      "9981438\n",
      "9981464\n",
      "10011866\n",
      "10012061\n",
      "10145198\n",
      "10145393\n",
      "10462810\n",
      "10462992\n",
      "10976626\n",
      "10976808\n",
      "10976834\n",
      "11261176\n",
      "11261358\n",
      "11261384\n",
      "11399657\n",
      "11399839\n",
      "11399865\n",
      "11667134\n",
      "11667355\n",
      "11988269\n",
      "11988464\n",
      "13237037\n",
      "13237219\n",
      "13250858\n",
      "13251079\n",
      "13887708\n",
      "13887903\n",
      "13887929\n",
      "13974428\n",
      "13974623\n",
      "13974649\n",
      "14966804\n",
      "14966830\n",
      "14966843\n",
      "14966856\n",
      "14966882\n",
      "14966960\n",
      "14967038\n",
      "15004499\n",
      "15004720\n",
      "16334296\n",
      "16334491\n",
      "16573047\n",
      "16573229\n",
      "16854616\n",
      "16854811\n",
      "16854837\n",
      "17241062\n",
      "17241270\n",
      "17388215\n",
      "17388397\n",
      "17388423\n",
      "17733469\n",
      "17733651\n",
      "18061108\n",
      "18061303\n",
      "18308802\n",
      "18309010\n",
      "18891181\n",
      "18891363\n",
      "19152967\n",
      "19153175\n",
      "19276814\n",
      "19277022\n",
      "19306895\n",
      "19307077\n",
      "20089814\n",
      "20090022\n",
      "20822327\n",
      "20822522\n",
      "21136958\n",
      "21137153\n",
      "21397118\n",
      "21397300\n",
      "21916625\n",
      "21916820\n",
      "22139116\n",
      "22139311\n",
      "22139337\n",
      "22386810\n",
      "22386992\n",
      "23118239\n",
      "23118460\n",
      "23303874\n",
      "23304056\n",
      "23304082\n",
      "24226087\n",
      "24226282\n",
      "24357251\n",
      "24357459\n",
      "26281325\n",
      "26281351\n",
      "26281364\n",
      "26281377\n",
      "26281403\n",
      "26281481\n",
      "26281559\n",
      "26572134\n",
      "26572316\n",
      "26764002\n",
      "26764184\n",
      "26866711\n",
      "26866906\n",
      "26866932\n",
      "27205461\n",
      "27205643\n",
      "27205669\n",
      "27471312\n",
      "27471494\n",
      "27520363\n",
      "27520571\n",
      "27688112\n",
      "27688307\n",
      "27712502\n",
      "27712684\n",
      "28804361\n",
      "28804569\n",
      "28879428\n",
      "28879610\n",
      "30527650\n",
      "30527832\n",
      "30595671\n",
      "30595853\n",
      "30924936\n",
      "30925131\n",
      "31702164\n",
      "31702359\n",
      "31891864\n",
      "31892072\n",
      "31941457\n",
      "31941678\n",
      "32302971\n",
      "32303153\n",
      "32450937\n",
      "32451132\n",
      "32451158\n",
      "32611098\n",
      "32611293\n",
      "32637927\n",
      "32638135\n",
      "32841990\n",
      "32842211\n",
      "32968547\n",
      "32968729\n",
      "32968755\n",
      "34047940\n",
      "34048135\n",
      "34048161\n",
      "34198345\n",
      "34198540\n",
      "34198566\n",
      "34783163\n",
      "34783345\n",
      "34783384\n",
      "34828691\n",
      "34828899\n",
      "34966630\n",
      "34966812\n",
      "34966838\n",
      "34994272\n",
      "34994454\n",
      "34994480\n",
      "35092916\n",
      "35093111\n",
      "35256058\n",
      "35256253\n",
      "35570147\n",
      "35570355\n",
      "36229219\n",
      "36229427\n",
      "36896692\n",
      "36896900\n",
      "37028940\n",
      "37029148\n",
      "37080159\n",
      "37080354\n",
      "37654137\n",
      "37654358\n",
      "38110501\n",
      "38110722\n",
      "39023771\n",
      "39023979\n",
      "39617261\n",
      "39617456\n",
      "39617482\n",
      "39929182\n",
      "39929390\n",
      "40063598\n",
      "40063806\n",
      "40102893\n",
      "40103088\n",
      "40138936\n",
      "40139144\n",
      "40181212\n",
      "40181420\n",
      "40526466\n",
      "40526648\n",
      "40526674\n",
      "40642996\n",
      "40643217\n",
      "40712372\n",
      "40712580\n",
      "41017789\n",
      "41017984\n",
      "42255175\n",
      "42255357\n",
      "42255383\n",
      "42538912\n",
      "42539120\n",
      "42566283\n",
      "42566491\n",
      "42733219\n",
      "42733414\n",
      "42913976\n",
      "42914158\n",
      "43920470\n",
      "43920652\n",
      "43920678\n",
      "43927787\n",
      "43927969\n",
      "44788483\n",
      "44788691\n",
      "44973847\n",
      "44974029\n",
      "45285768\n",
      "45285950\n",
      "45756766\n",
      "45756987\n",
      "45881426\n",
      "45881621\n",
      "45970043\n",
      "45970225\n",
      "46227222\n",
      "46227417\n",
      "46257303\n",
      "46257511\n",
      "46846457\n",
      "46846639\n",
      "46860278\n",
      "46860486\n",
      "47135614\n",
      "47135835\n",
      "47776258\n",
      "47776479\n",
      "48211755\n",
      "48211976\n",
      "48730720\n",
      "48730902\n",
      "48958631\n",
      "48958839\n",
      "49052939\n",
      "49053134\n",
      "49181935\n",
      "49182117\n",
      "49531254\n",
      "49531462\n",
      "49629085\n",
      "49629280\n",
      "50109568\n",
      "50109763\n",
      "50351029\n",
      "50351250\n",
      "50915522\n",
      "50915730\n",
      "51435300\n",
      "51435521\n",
      "51529608\n",
      "51529790\n",
      "51549120\n",
      "51549341\n",
      "52394369\n",
      "52394577\n",
      "54132021\n",
      "54132216\n",
      "54801120\n",
      "54801328\n",
      "55339868\n",
      "55340050\n",
      "55498403\n",
      "55498598\n",
      "57316000\n",
      "57316195\n",
      "57389170\n",
      "57389378\n",
      "58763411\n",
      "58763606\n",
      "60852279\n",
      "60852487\n",
      "60929785\n",
      "60929980\n",
      "61063659\n",
      "61063880\n",
      "61078293\n",
      "61078501\n",
      "61270161\n",
      "61270343\n",
      "61386962\n",
      "61387170\n",
      "64468774\n",
      "64468956\n",
      "64688284\n",
      "64688479\n",
      "65197764\n",
      "65197946\n",
      "65197972\n",
      "65611581\n",
      "65611763\n",
      "65648708\n",
      "65648890\n",
      "66480949\n",
      "66481157\n",
      "66558726\n",
      "66558934\n",
      "67910203\n",
      "67910398\n",
      "67910424\n"
     ]
    }
   ],
   "source": [
    "# Removes points with nan. It is assumed that these are all magnitude measurements, so they are set to their max.\n",
    "flat = catalog.flatten()\n",
    "for i in range(flat.size):\n",
    "    if (np.isnan(flat[i])) or (not np.isfinite(flat[i])):\n",
    "        catalog[i//271][i%271] = 99.999\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_predictions=knn.predict(catalog) # Contains the predicted good/bad points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = np.zeros((catalog.shape[0],2))\n",
    "allinfo = np.zeros(np.shape(catalog))\n",
    "\n",
    "j = 0 # Iteration variable for positions array\n",
    "for i in range(catalog.shape[0]): # Cycles through each object in catalog\n",
    "    # Checks to make sure point is \"good\"\n",
    "    # Good defined by: 1. S/N > 20     2. Sharpness < .25     3. Roundness < 1     4. Crowding < .1 \n",
    "    #                  5. Object type = \"Bright Star\"     6. ML algorithm picks as good\n",
    "    if ((catalog[i][5] >= 20)&(abs(catalog[i][6]) < .25)&(abs(catalog[i][7]) < 1)\n",
    "        &(catalog[i][9] < .1)&(catalog[i][10] == 1)&(cat_predictions[i] == 'green')):\n",
    "        pos[j][0] = catalog[i][2] # Assigns X position with offset\n",
    "        pos[j][1] = catalog[i][3] # Assigns Y position with offset\n",
    "        allinfo[j] = catalog[i]\n",
    "        j = j + 1\n",
    "                \n",
    "# Trims all zeros from end of positions array, left from objects with low S/N\n",
    "pos = pos[~np.all(pos == 0, axis=1)]\n",
    "info = allinfo[~np.all(allinfo == 0, axis=1)]\n",
    "\n",
    "# Saves high S/N object X,Y positions\n",
    "np.savetxt(\"sn2010ae_ML1.reg\", pos, '%5.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2656, 271)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train, this time with lower signal to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asci = open(\"/Users/tktakaro/Documents/Type1ax_HST/machine_learning/sn2010ae_set2.reg\", \"r+\")\n",
    "\n",
    "def mysplit(s, delim=None):\n",
    "    return [x for x in s.split(delim) if x]\n",
    "\n",
    "text = asci.readlines()\n",
    "regionX = np.zeros(2676)\n",
    "regionY = np.zeros(2676)\n",
    "key = []\n",
    "for i in range(2676):\n",
    "    A = mysplit(text[i+3], ' # ')\n",
    "    regionX[i] = mysplit(mysplit(A[0], 'point')[0],',')[0][1:]\n",
    "    regionY[i] = mysplit(mysplit(A[0], 'point')[0],',')[1][:-1]\n",
    "    if A[1][-3] == 'l':\n",
    "        key.append('green')\n",
    "    elif A[1][-3] == 'u':\n",
    "        key.append('blue')\n",
    "    else:\n",
    "        print(\"Error: neither blue nor green\")\n",
    "\n",
    "# Remove points from info (that were removed by hand)\n",
    "j = 0\n",
    "for i in range(info.shape[0]):\n",
    "    if (info[i][2] == regionX[j]) & (info[i][3] == regionY[j]):\n",
    "        j = j + 1\n",
    "    else:\n",
    "        info[i] = np.zeros(271)\n",
    "info = info[~np.all(info == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pandas.DataFrame(info)\n",
    "dataset[271] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:271]\n",
    "Y = array[:,271]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,\n",
    "                                                    test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.830745 (0.027459)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.779172 (0.047930)\n",
      "KNN: 0.839358 (0.037043)\n",
      "CART: 0.799255 (0.035765)\n",
      "NB: 0.820725 (0.038864)\n",
      "SVM: 0.747516 (0.043974)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAESCAYAAAAG+ZUXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8uQg7uZWYYc3M3MMuTgbmaWof8P+RSl5BVfrNQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d558518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845149253731\n",
      "[[ 91  49]\n",
      " [ 34 362]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       blue       0.73      0.65      0.69       140\n",
      "      green       0.88      0.91      0.90       396\n",
      "\n",
      "avg / total       0.84      0.85      0.84       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_predictions=knn.predict(catalog) # Contains the predicted good/bad points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = np.zeros((catalog.shape[0],2))\n",
    "allinfo = np.zeros(np.shape(catalog))\n",
    "\n",
    "j = 0 # Iteration variable for positions array\n",
    "for i in range(catalog.shape[0]): # Cycles through each object in catalog\n",
    "    # Checks to make sure point is \"good\"\n",
    "    # Good defined by: 1. S/N > 5     2. Sharpness < .25     3. Roundness < 1     4. Crowding < .1 \n",
    "    #                  5. Object type = \"Bright Star\"     6. ML algorithm picks as good\n",
    "    if ((catalog[i][5] >= 10)&(abs(catalog[i][6]) < .25)&(abs(catalog[i][7]) < 1)\n",
    "        &(catalog[i][9] < .1)&(catalog[i][10] == 1)&(cat_predictions[i] == 'green')):\n",
    "        pos[j][0] = catalog[i][2] # Assigns X position with offset\n",
    "        pos[j][1] = catalog[i][3] # Assigns Y position with offset\n",
    "        allinfo[j] = catalog[i]\n",
    "        j = j + 1\n",
    "                \n",
    "# Trims all zeros from end of positions array, left from objects with low S/N\n",
    "pos = pos[~np.all(pos == 0, axis=1)]\n",
    "info = allinfo[~np.all(allinfo == 0, axis=1)]\n",
    "\n",
    "# Saves high S/N object X,Y positions\n",
    "np.savetxt(\"sn2010ae_ML2.reg\", pos, '%5.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5034, 271)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
