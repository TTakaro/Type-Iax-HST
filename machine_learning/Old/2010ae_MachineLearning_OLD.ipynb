{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalog = np.loadtxt(\"/Users/tktakaro/Documents/Type1ax_HST/curtis_files/sn2010ae/sn2010ae.phot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asci = open(\"/Users/tktakaro/Documents/Type1ax_HST/machine_learning/sn2010ae_set.reg\", \"r+\")\n",
    "\n",
    "def mysplit(s, delim=None):\n",
    "    return [x for x in s.split(delim) if x]\n",
    "\n",
    "text = asci.readlines()\n",
    "regionX = np.zeros(871)\n",
    "regionY = np.zeros(871)\n",
    "key = []\n",
    "for i in range(871):\n",
    "    A = mysplit(text[i+3], ' # ')\n",
    "    regionX[i] = mysplit(mysplit(A[0], 'point')[0],',')[0][1:]\n",
    "    regionY[i] = mysplit(mysplit(A[0], 'point')[0],',')[1][:-1]\n",
    "    if A[1][-3] == 'l':\n",
    "        key.append('green')\n",
    "    elif A[1][-3] == 'u':\n",
    "        key.append('blue')\n",
    "    else:\n",
    "        print(\"Error: neither blue nor green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a array with a space for each object in the catalog, to contain only X,Y positions\n",
    "positions = np.zeros([np.shape(catalog)[0], 2])\n",
    "allinfo = np.zeros(np.shape(catalog))\n",
    "\n",
    "j = 0 # Iteration variable for positions array\n",
    "for i in range(catalog.shape[0]): # Cycles through each object in catalog\n",
    "    # Checks for a S/N ratio of 50 or greater (to be lowered later)\n",
    "    if ((catalog[i][5] >= 50)&(abs(catalog[i][6]) < .25)&(abs(catalog[i][7]) < 1)\n",
    "        &(catalog[i][9] < .1)&(catalog[i][10] == 1)):\n",
    "        positions[j][0] = catalog[i][2] # Assigns X position with offset\n",
    "        positions[j][1] = catalog[i][3] # Assigns Y position with offset\n",
    "        allinfo[j] = catalog[i]\n",
    "        j = j + 1\n",
    "\n",
    "# Trims all zeros from end of positions array, left from objects with low S/N\n",
    "pos = positions[~np.all(positions == 0, axis=1)]\n",
    "info = allinfo[~np.all(allinfo == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolor1 = np.zeros(info.shape[0])\\ncolor2 = np.zeros(info.shape[0])\\ncolor3 = np.zeros(info.shape[0])\\ncolor4 = np.zeros(info.shape[0])\\ncolor5 = np.zeros(info.shape[0])\\ncolor6 = np.zeros(info.shape[0])\\nfor i in range(info.shape[0]):\\n    color1[i] = info[i][50] - info[i][37]\\n    color2[i] = info[i][50] - info[i][24]\\n    color3[i] = info[i][50] - info[i][11]\\n    color4[i] = info[i][37] - info[i][24]\\n    color5[i] = info[i][37] - info[i][11]\\n    color6[i] = info[i][24] - info[i][11]   \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding in colors (Deprecated)\n",
    "# F435W counts: 11, F555W counts: 24, F625W counts: 37, F814W counts: 50\n",
    "\"\"\"\n",
    "color1 = np.zeros(info.shape[0])\n",
    "color2 = np.zeros(info.shape[0])\n",
    "color3 = np.zeros(info.shape[0])\n",
    "color4 = np.zeros(info.shape[0])\n",
    "color5 = np.zeros(info.shape[0])\n",
    "color6 = np.zeros(info.shape[0])\n",
    "for i in range(info.shape[0]):\n",
    "    color1[i] = info[i][50] - info[i][37]\n",
    "    color2[i] = info[i][50] - info[i][24]\n",
    "    color3[i] = info[i][50] - info[i][11]\n",
    "    color4[i] = info[i][37] - info[i][24]\n",
    "    color5[i] = info[i][37] - info[i][11]\n",
    "    color6[i] = info[i][24] - info[i][11]   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "(871, 2)\n",
      "(871, 271)\n"
     ]
    }
   ],
   "source": [
    "for i in range(pos.shape[0]):\n",
    "    if (pos[i][0] > 3200) & (pos[i][0] < 3300) & (pos[i][1] > 800) & (pos[i][1] < 900):\n",
    "        print(i)\n",
    "\n",
    "pos[317] = np.zeros(2)\n",
    "info[317] = np.zeros(271)\n",
    "pos = pos[~np.all(pos == 0, axis=1)]\n",
    "info = info[~np.all(info == 0, axis=1)]\n",
    "print(pos.shape)\n",
    "print(info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pandas.DataFrame(info)\n",
    "#dataset[271] = color1\n",
    "#dataset[272] = color2\n",
    "#dataset[273] = color3\n",
    "#dataset[274] = color4\n",
    "#dataset[275] = color5\n",
    "#dataset[276] = color6\n",
    "dataset[271] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:271]\n",
    "Y = array[:,271]\n",
    "validation_size = 0.20\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "42\n",
      "379\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "flat = X.flatten()\n",
    "for i in range(flat.size):\n",
    "    if (np.isnan(flat[i])) or (not np.isfinite(flat[i])):\n",
    "        print(i//271)\n",
    "        print(i%271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replaces values which were previously NaN\n",
    "X[379][224] = 99.999\n",
    "X[379][42] = 99.999\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,\n",
    "                                                    test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.872381 (0.053657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.832029 (0.036207)\n",
      "KNN: 0.902422 (0.027452)\n",
      "CART: 0.870559 (0.042297)\n",
      "NB: 0.846439 (0.058901)\n",
      "SVM: 0.817847 (0.072044)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAESCAYAAAAG+ZUXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVkJObibmZXQ/wdsosKYoYPkSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bc4358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914285714286\n",
      "[[  7  13]\n",
      " [  2 153]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       blue       0.78      0.35      0.48        20\n",
      "      green       0.92      0.99      0.95       155\n",
      "\n",
      "avg / total       0.91      0.91      0.90       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now apply algorithm to catalog at large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111397\n",
      "111423\n",
      "111436\n",
      "111488\n",
      "111592\n",
      "111644\n",
      "187845\n",
      "188040\n",
      "190826\n",
      "191021\n",
      "203563\n",
      "203745\n",
      "207873\n",
      "207899\n",
      "207912\n",
      "207925\n",
      "208029\n",
      "208081\n",
      "216300\n",
      "216495\n",
      "231179\n",
      "231205\n",
      "231218\n",
      "231231\n",
      "231335\n",
      "231387\n",
      "241232\n",
      "241427\n",
      "255053\n",
      "255248\n",
      "256137\n",
      "256358\n",
      "302723\n",
      "302749\n",
      "302762\n",
      "302814\n",
      "302918\n",
      "302970\n",
      "303291\n",
      "303512\n",
      "304620\n",
      "304646\n",
      "304659\n",
      "304685\n",
      "304789\n",
      "304841\n",
      "318467\n",
      "318688\n",
      "342586\n",
      "342781\n",
      "440688\n",
      "440883\n",
      "460742\n",
      "460924\n",
      "466975\n",
      "467196\n",
      "489468\n",
      "489650\n",
      "494346\n",
      "494541\n",
      "496759\n",
      "496785\n",
      "496798\n",
      "496811\n",
      "496915\n",
      "496967\n",
      "509251\n",
      "509433\n",
      "517110\n",
      "517331\n",
      "537164\n",
      "537346\n",
      "570226\n",
      "570421\n",
      "588654\n",
      "588875\n",
      "593532\n",
      "593740\n",
      "594616\n",
      "594798\n",
      "606811\n",
      "607019\n",
      "609250\n",
      "609445\n",
      "634724\n",
      "634906\n",
      "637705\n",
      "637913\n",
      "637950\n",
      "637976\n",
      "637989\n",
      "638028\n",
      "638132\n",
      "638184\n",
      "639060\n",
      "639242\n",
      "639268\n",
      "655565\n",
      "655591\n",
      "655604\n",
      "655656\n",
      "655760\n",
      "655812\n",
      "655862\n",
      "656057\n",
      "659656\n",
      "659838\n",
      "664263\n",
      "664445\n",
      "679955\n",
      "679981\n",
      "679994\n",
      "680007\n",
      "680033\n",
      "680111\n",
      "680137\n",
      "680163\n",
      "680189\n",
      "685130\n",
      "685338\n",
      "692718\n",
      "692913\n",
      "692989\n",
      "693210\n",
      "700577\n",
      "700759\n",
      "704100\n",
      "704321\n",
      "714127\n",
      "714309\n",
      "727109\n",
      "727135\n",
      "727148\n",
      "727200\n",
      "727304\n",
      "727356\n",
      "729277\n",
      "729303\n",
      "729316\n",
      "729342\n",
      "729368\n",
      "729446\n",
      "729498\n",
      "729524\n",
      "733097\n",
      "733318\n",
      "752067\n",
      "752262\n",
      "757487\n",
      "757669\n",
      "774018\n",
      "774239\n",
      "777270\n",
      "777465\n",
      "802202\n",
      "802423\n",
      "811145\n",
      "811340\n",
      "830386\n",
      "830568\n",
      "837432\n",
      "837614\n",
      "843123\n",
      "843305\n",
      "843331\n",
      "857486\n",
      "857707\n",
      "873475\n",
      "873657\n",
      "881334\n",
      "881555\n",
      "886728\n",
      "886754\n",
      "886767\n",
      "886793\n",
      "886897\n",
      "886949\n",
      "890277\n",
      "890498\n",
      "896755\n",
      "896781\n",
      "896794\n",
      "896807\n",
      "896911\n",
      "896963\n",
      "926320\n",
      "926515\n",
      "928217\n",
      "928425\n",
      "974016\n",
      "974224\n",
      "975345\n",
      "975371\n",
      "975384\n",
      "975410\n",
      "975514\n",
      "975566\n",
      "985940\n",
      "986135\n",
      "990818\n",
      "991013\n",
      "1004910\n",
      "1005131\n",
      "1007865\n",
      "1007891\n",
      "1007904\n",
      "1007917\n",
      "1007943\n",
      "1008021\n",
      "1008073\n",
      "1008099\n",
      "1012743\n",
      "1012769\n",
      "1012782\n",
      "1012808\n",
      "1012912\n",
      "1012964\n",
      "1015750\n",
      "1015945\n",
      "1019273\n",
      "1019455\n",
      "1019481\n",
      "1020899\n",
      "1021107\n",
      "1036888\n",
      "1037070\n",
      "1042011\n",
      "1042037\n",
      "1042050\n",
      "1042102\n",
      "1042206\n",
      "1042258\n",
      "1045560\n",
      "1045781\n",
      "1050980\n",
      "1051188\n",
      "1061820\n",
      "1062015\n",
      "1097592\n",
      "1097787\n",
      "1097813\n",
      "1102741\n",
      "1102962\n",
      "1104909\n",
      "1105104\n",
      "1117917\n",
      "1118125\n",
      "1131983\n",
      "1132009\n",
      "1132022\n",
      "1132048\n",
      "1132152\n",
      "1132204\n",
      "1162903\n",
      "1163111\n",
      "1180789\n",
      "1180997\n",
      "1195152\n",
      "1195373\n",
      "1229840\n",
      "1230061\n",
      "1230924\n",
      "1231106\n",
      "1236615\n",
      "1236836\n",
      "1243390\n",
      "1243572\n",
      "1300274\n",
      "1300300\n",
      "1300313\n",
      "1300339\n",
      "1300365\n",
      "1300443\n",
      "1300521\n",
      "1356939\n",
      "1357160\n",
      "1378890\n",
      "1379072\n",
      "1391898\n",
      "1392093\n",
      "1400299\n",
      "1400481\n",
      "1406803\n",
      "1407011\n",
      "1444717\n",
      "1444743\n",
      "1444756\n",
      "1444782\n",
      "1444808\n",
      "1444886\n",
      "1444912\n",
      "1444938\n",
      "1444964\n",
      "1450434\n",
      "1450616\n",
      "1450642\n",
      "1452873\n",
      "1453081\n",
      "1469946\n",
      "1470128\n",
      "1500840\n",
      "1501061\n",
      "1510841\n",
      "1510867\n",
      "1510880\n",
      "1510893\n",
      "1510919\n",
      "1511023\n",
      "1511049\n",
      "1518997\n",
      "1519192\n",
      "1519218\n",
      "1527669\n",
      "1527864\n",
      "1527890\n",
      "1553956\n",
      "1554138\n",
      "1581327\n",
      "1581548\n",
      "1602194\n",
      "1602376\n",
      "1610324\n",
      "1610506\n",
      "1652871\n",
      "1653066\n",
      "1665879\n",
      "1666074\n",
      "1729564\n",
      "1729772\n",
      "1730106\n",
      "1730301\n",
      "1744985\n",
      "1745011\n",
      "1745024\n",
      "1745076\n",
      "1745180\n",
      "1745232\n",
      "1785635\n",
      "1785661\n",
      "1785674\n",
      "1785687\n",
      "1785791\n",
      "1785843\n",
      "1826827\n",
      "1826853\n",
      "1826866\n",
      "1826879\n",
      "1826905\n",
      "1826983\n",
      "1827009\n",
      "1827061\n",
      "1881324\n",
      "1881532\n",
      "1894061\n",
      "1894243\n",
      "1894269\n",
      "1920348\n",
      "1920543\n",
      "1922787\n",
      "1922982\n",
      "1925768\n",
      "1925963\n",
      "1959617\n",
      "1959643\n",
      "1959656\n",
      "1959669\n",
      "1959695\n",
      "1959773\n",
      "1959799\n",
      "1959825\n",
      "1959851\n",
      "1965063\n",
      "1965245\n",
      "1985930\n",
      "1986138\n",
      "2013030\n",
      "2013225\n",
      "2148801\n",
      "2149022\n",
      "2196742\n",
      "2196768\n",
      "2196781\n",
      "2196807\n",
      "2196911\n",
      "2196963\n",
      "2341753\n",
      "2341935\n",
      "2392701\n",
      "2392896\n",
      "2441481\n",
      "2441702\n",
      "2471020\n",
      "2471241\n",
      "2476982\n",
      "2477177\n",
      "2481860\n",
      "2482055\n",
      "2530098\n",
      "2530280\n",
      "2590531\n",
      "2590713\n",
      "2590739\n",
      "2645544\n",
      "2645765\n",
      "2941476\n",
      "2941658\n",
      "3038739\n",
      "3038765\n",
      "3038778\n",
      "3038830\n",
      "3038934\n",
      "3038986\n",
      "3047140\n",
      "3047166\n",
      "3047179\n",
      "3047205\n",
      "3047231\n",
      "3047335\n",
      "3047361\n",
      "3047387\n",
      "3068846\n",
      "3069054\n",
      "3083209\n",
      "3083391\n",
      "3133886\n",
      "3134094\n",
      "3149875\n",
      "3150096\n",
      "3162612\n",
      "3162794\n",
      "3162820\n",
      "3320063\n",
      "3320245\n",
      "3321147\n",
      "3321342\n",
      "3575616\n",
      "3575811\n",
      "3609491\n",
      "3609673\n",
      "3630087\n",
      "3630295\n",
      "3800004\n",
      "3800186\n",
      "3915992\n",
      "3916174\n",
      "3959081\n",
      "3959263\n",
      "4068565\n",
      "4068760\n",
      "4068786\n",
      "4192683\n",
      "4192865\n",
      "4368562\n",
      "4368783\n",
      "4543086\n",
      "4543268\n",
      "4543294\n",
      "4712164\n",
      "4712190\n",
      "4712203\n",
      "4712216\n",
      "4712242\n",
      "4712320\n",
      "4712346\n",
      "4712372\n",
      "4728450\n",
      "4728645\n",
      "4794574\n",
      "4794756\n",
      "4794782\n",
      "4876687\n",
      "4876882\n",
      "4876908\n",
      "4895657\n",
      "4895852\n",
      "5025711\n",
      "5025737\n",
      "5025750\n",
      "5025763\n",
      "5025789\n",
      "5025867\n",
      "5025919\n",
      "5082918\n",
      "5083126\n",
      "5446032\n",
      "5446058\n",
      "5446071\n",
      "5446123\n",
      "5446227\n",
      "5446279\n",
      "5612181\n",
      "5612402\n",
      "5715161\n",
      "5715382\n",
      "5745513\n",
      "5745734\n",
      "5881826\n",
      "5882021\n",
      "5882047\n",
      "6383447\n",
      "6383629\n",
      "6595072\n",
      "6595098\n",
      "6595111\n",
      "6595124\n",
      "6595228\n",
      "6595306\n",
      "6595640\n",
      "6595822\n",
      "6595848\n",
      "6849296\n",
      "6849517\n",
      "6879106\n",
      "6879288\n",
      "6879314\n",
      "7115392\n",
      "7115418\n",
      "7115431\n",
      "7115444\n",
      "7115470\n",
      "7115574\n",
      "7115600\n",
      "7115626\n",
      "7524628\n",
      "7524823\n",
      "7854706\n",
      "7854927\n",
      "8362289\n",
      "8362497\n",
      "8369335\n",
      "8369530\n",
      "8688302\n",
      "8688510\n",
      "8908354\n",
      "8908549\n",
      "8908575\n",
      "9089924\n",
      "9090132\n",
      "9676368\n",
      "9676589\n",
      "9899943\n",
      "9900138\n",
      "9900164\n",
      "9981243\n",
      "9981438\n",
      "9981464\n",
      "10011866\n",
      "10012061\n",
      "10145198\n",
      "10145393\n",
      "10462810\n",
      "10462992\n",
      "10976626\n",
      "10976808\n",
      "10976834\n",
      "11261176\n",
      "11261358\n",
      "11261384\n",
      "11399657\n",
      "11399839\n",
      "11399865\n",
      "11667134\n",
      "11667355\n",
      "11988269\n",
      "11988464\n",
      "13237037\n",
      "13237219\n",
      "13250858\n",
      "13251079\n",
      "13887708\n",
      "13887903\n",
      "13887929\n",
      "13974428\n",
      "13974623\n",
      "13974649\n",
      "14966804\n",
      "14966830\n",
      "14966843\n",
      "14966856\n",
      "14966882\n",
      "14966960\n",
      "14967038\n",
      "15004499\n",
      "15004720\n",
      "16334296\n",
      "16334491\n",
      "16573047\n",
      "16573229\n",
      "16854616\n",
      "16854811\n",
      "16854837\n",
      "17241062\n",
      "17241270\n",
      "17388215\n",
      "17388397\n",
      "17388423\n",
      "17733469\n",
      "17733651\n",
      "18061108\n",
      "18061303\n",
      "18308802\n",
      "18309010\n",
      "18891181\n",
      "18891363\n",
      "19152967\n",
      "19153175\n",
      "19276814\n",
      "19277022\n",
      "19306895\n",
      "19307077\n",
      "20089814\n",
      "20090022\n",
      "20822327\n",
      "20822522\n",
      "21136958\n",
      "21137153\n",
      "21397118\n",
      "21397300\n",
      "21916625\n",
      "21916820\n",
      "22139116\n",
      "22139311\n",
      "22139337\n",
      "22386810\n",
      "22386992\n",
      "23118239\n",
      "23118460\n",
      "23303874\n",
      "23304056\n",
      "23304082\n",
      "24226087\n",
      "24226282\n",
      "24357251\n",
      "24357459\n",
      "26281325\n",
      "26281351\n",
      "26281364\n",
      "26281377\n",
      "26281403\n",
      "26281481\n",
      "26281559\n",
      "26572134\n",
      "26572316\n",
      "26764002\n",
      "26764184\n",
      "26866711\n",
      "26866906\n",
      "26866932\n",
      "27205461\n",
      "27205643\n",
      "27205669\n",
      "27471312\n",
      "27471494\n",
      "27520363\n",
      "27520571\n",
      "27688112\n",
      "27688307\n",
      "27712502\n",
      "27712684\n",
      "28804361\n",
      "28804569\n",
      "28879428\n",
      "28879610\n",
      "30527650\n",
      "30527832\n",
      "30595671\n",
      "30595853\n",
      "30924936\n",
      "30925131\n",
      "31702164\n",
      "31702359\n",
      "31891864\n",
      "31892072\n",
      "31941457\n",
      "31941678\n",
      "32302971\n",
      "32303153\n",
      "32450937\n",
      "32451132\n",
      "32451158\n",
      "32611098\n",
      "32611293\n",
      "32637927\n",
      "32638135\n",
      "32841990\n",
      "32842211\n",
      "32968547\n",
      "32968729\n",
      "32968755\n",
      "34047940\n",
      "34048135\n",
      "34048161\n",
      "34198345\n",
      "34198540\n",
      "34198566\n",
      "34783163\n",
      "34783345\n",
      "34783384\n",
      "34828691\n",
      "34828899\n",
      "34966630\n",
      "34966812\n",
      "34966838\n",
      "34994272\n",
      "34994454\n",
      "34994480\n",
      "35092916\n",
      "35093111\n",
      "35256058\n",
      "35256253\n",
      "35570147\n",
      "35570355\n",
      "36229219\n",
      "36229427\n",
      "36896692\n",
      "36896900\n",
      "37028940\n",
      "37029148\n",
      "37080159\n",
      "37080354\n",
      "37654137\n",
      "37654358\n",
      "38110501\n",
      "38110722\n",
      "39023771\n",
      "39023979\n",
      "39617261\n",
      "39617456\n",
      "39617482\n",
      "39929182\n",
      "39929390\n",
      "40063598\n",
      "40063806\n",
      "40102893\n",
      "40103088\n",
      "40138936\n",
      "40139144\n",
      "40181212\n",
      "40181420\n",
      "40526466\n",
      "40526648\n",
      "40526674\n",
      "40642996\n",
      "40643217\n",
      "40712372\n",
      "40712580\n",
      "41017789\n",
      "41017984\n",
      "42255175\n",
      "42255357\n",
      "42255383\n",
      "42538912\n",
      "42539120\n",
      "42566283\n",
      "42566491\n",
      "42733219\n",
      "42733414\n",
      "42913976\n",
      "42914158\n",
      "43920470\n",
      "43920652\n",
      "43920678\n",
      "43927787\n",
      "43927969\n",
      "44788483\n",
      "44788691\n",
      "44973847\n",
      "44974029\n",
      "45285768\n",
      "45285950\n",
      "45756766\n",
      "45756987\n",
      "45881426\n",
      "45881621\n",
      "45970043\n",
      "45970225\n",
      "46227222\n",
      "46227417\n",
      "46257303\n",
      "46257511\n",
      "46846457\n",
      "46846639\n",
      "46860278\n",
      "46860486\n",
      "47135614\n",
      "47135835\n",
      "47776258\n",
      "47776479\n",
      "48211755\n",
      "48211976\n",
      "48730720\n",
      "48730902\n",
      "48958631\n",
      "48958839\n",
      "49052939\n",
      "49053134\n",
      "49181935\n",
      "49182117\n",
      "49531254\n",
      "49531462\n",
      "49629085\n",
      "49629280\n",
      "50109568\n",
      "50109763\n",
      "50351029\n",
      "50351250\n",
      "50915522\n",
      "50915730\n",
      "51435300\n",
      "51435521\n",
      "51529608\n",
      "51529790\n",
      "51549120\n",
      "51549341\n",
      "52394369\n",
      "52394577\n",
      "54132021\n",
      "54132216\n",
      "54801120\n",
      "54801328\n",
      "55339868\n",
      "55340050\n",
      "55498403\n",
      "55498598\n",
      "57316000\n",
      "57316195\n",
      "57389170\n",
      "57389378\n",
      "58763411\n",
      "58763606\n",
      "60852279\n",
      "60852487\n",
      "60929785\n",
      "60929980\n",
      "61063659\n",
      "61063880\n",
      "61078293\n",
      "61078501\n",
      "61270161\n",
      "61270343\n",
      "61386962\n",
      "61387170\n",
      "64468774\n",
      "64468956\n",
      "64688284\n",
      "64688479\n",
      "65197764\n",
      "65197946\n",
      "65197972\n",
      "65611581\n",
      "65611763\n",
      "65648708\n",
      "65648890\n",
      "66480949\n",
      "66481157\n",
      "66558726\n",
      "66558934\n",
      "67910203\n",
      "67910398\n",
      "67910424\n"
     ]
    }
   ],
   "source": [
    "# Removes points with nan. It is assumed that these are all magnitude measurements, so they are set to their max.\n",
    "flat = catalog.flatten()\n",
    "for i in range(flat.size):\n",
    "    if (np.isnan(flat[i])) or (not np.isfinite(flat[i])):\n",
    "        catalog[i//271][i%271] = 99.999\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_predictions=knn.predict(catalog) # Contains the predicted good/bad points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = np.zeros((catalog.shape[0],2))\n",
    "allinfo = np.zeros(np.shape(catalog))\n",
    "\n",
    "j = 0 # Iteration variable for positions array\n",
    "for i in range(catalog.shape[0]): # Cycles through each object in catalog\n",
    "    # Checks to make sure point is \"good\"\n",
    "    # Good defined by: 1. S/N > 20     2. Sharpness < .25     3. Roundness < 1     4. Crowding < .1 \n",
    "    #                  5. Object type = \"Bright Star\"     6. ML algorithm picks as good\n",
    "    if ((catalog[i][5] >= 20)&(abs(catalog[i][6]) < .25)&(abs(catalog[i][7]) < 1)\n",
    "        &(catalog[i][9] < .1)&(catalog[i][10] == 1)&(cat_predictions[i] == 'green')):\n",
    "        pos[j][0] = catalog[i][2] # Assigns X position with offset\n",
    "        pos[j][1] = catalog[i][3] # Assigns Y position with offset\n",
    "        allinfo[j] = catalog[i]\n",
    "        j = j + 1\n",
    "                \n",
    "# Trims all zeros from end of positions array, left from objects with low S/N\n",
    "pos = pos[~np.all(pos == 0, axis=1)]\n",
    "info = allinfo[~np.all(allinfo == 0, axis=1)]\n",
    "\n",
    "# Saves high S/N object X,Y positions\n",
    "np.savetxt(\"sn2010ae_ML1.reg\", pos, '%5.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is leftover junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 271)\n",
      "25.099\n",
      "23.694\n",
      "22.633\n",
      "20.954\n"
     ]
    }
   ],
   "source": [
    "print(info.shape)\n",
    "print(info[45][15])\n",
    "print(info[45][28])\n",
    "print(info[45][41])\n",
    "print(info[45][54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKZjWSZ6ki8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0545c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F45 = np.zeros(info.shape[0])\n",
    "F68 = np.zeros(info.shape[0])\n",
    "\n",
    "for i in range(info.shape[0]):\n",
    "    F45[i] = info[i][15] - info[i][28]\n",
    "    F68[i] = info[i][41] - info[i][54]\n",
    "\n",
    "#plt.plot(F68, F45, 'b.')\n",
    "#plt.axis([-1,3, -1,6])\n",
    "plt.plot(info[:][6], info[:][28], 'b.')\n",
    "plt.axis([-.02,0,-1,20])\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train, this time with lower signal to noise (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asci = open(\"/Users/tktakaro/Documents/Type1ax_HST/machine_learning/sn2010ae_set2.reg\", \"r+\")\n",
    "\n",
    "def mysplit(s, delim=None):\n",
    "    return [x for x in s.split(delim) if x]\n",
    "\n",
    "text = asci.readlines()\n",
    "regionX = np.zeros(2676)\n",
    "regionY = np.zeros(2676)\n",
    "info2 = np.zeros([2676,271])\n",
    "key = []\n",
    "\n",
    "j = 0\n",
    "for i in range(2679):\n",
    "    A = mysplit(text[i+3], ' # ')\n",
    "    if A[1][-3] != 'l':\n",
    "        regionX[j] = mysplit(mysplit(A[0], 'point')[0],',')[0][1:]\n",
    "        regionY[j] = mysplit(mysplit(A[0], 'point')[0],',')[1][:-1]\n",
    "        info2[j] = info[i+3]\n",
    "        j = j + 1\n",
    "    if A[1][-3] == 'u':\n",
    "        key.append('blue')\n",
    "    elif A[1][-3] == 'o':\n",
    "        key.append('yellow')\n",
    "    elif A[1][-3] == 'e':\n",
    "        key.append('red')\n",
    "\n",
    "info2 = info2[~np.all(info2 == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pandas.DataFrame(info2)\n",
    "dataset[271] = key\n",
    "\n",
    "\n",
    "array = dataset.values\n",
    "X = array[:,0:271]\n",
    "Y = array[:,271]\n",
    "validation_size = 0.20\n",
    "seed = 5\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,\n",
    "                                                    test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train, this time with lower signal to noise (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asci = open(\"/Users/tktakaro/Documents/Type1ax_HST/machine_learning/Working_SN20_ML1(2_Colors).reg\", \"r+\")\n",
    "\n",
    "def mysplit(s, delim=None):\n",
    "    return [x for x in s.split(delim) if x]\n",
    "\n",
    "text = asci.readlines()\n",
    "regionX = np.zeros(2656)\n",
    "regionY = np.zeros(2656)\n",
    "info2 = np.zeros([2656,271])\n",
    "key = []\n",
    "\n",
    "j = 0\n",
    "for i in range(2653):\n",
    "    A = mysplit(text[i+3], ' # ')\n",
    "    if A[1][-3] != 'l':\n",
    "        regionX[j] = mysplit(mysplit(A[0], 'point')[0],',')[0][1:]\n",
    "        regionY[j] = mysplit(mysplit(A[0], 'point')[0],',')[1][:-1]\n",
    "        info2[j] = info[i+3]\n",
    "        j = j + 1\n",
    "    if A[1][-3] == 'u':\n",
    "        key.append('blue')\n",
    "    elif A[1][-3] == 'o':\n",
    "        key.append('yellow')\n",
    "    elif A[1][-3] == 'e':\n",
    "        key.append('red')\n",
    "\n",
    "info2 = info2[~np.all(info2 == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pandas.DataFrame(info2)\n",
    "dataset[271] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:271]\n",
    "Y = array[:,271]\n",
    "validation_size = 0.20\n",
    "seed = 5\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,\n",
    "                                                    test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.689664 (0.067256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.606387 (0.056700)\n",
      "KNN: 0.709664 (0.056840)\n",
      "CART: 0.652605 (0.050051)\n",
      "NB: 0.511429 (0.114428)\n",
      "SVM: 0.545714 (0.062935)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAESCAYAAAAL5+VQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d6a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64367816092\n",
      "[[31 13]\n",
      " [18 25]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       blue       0.63      0.70      0.67        44\n",
      "     yellow       0.66      0.58      0.62        43\n",
      "\n",
      "avg / total       0.65      0.64      0.64        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_predictions=knn.predict(catalog) # Contains the predicted good/bad points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = np.zeros((catalog.shape[0],2))\n",
    "allinfo = np.zeros(np.shape(catalog))\n",
    "\n",
    "j = 0 # Iteration variable for positions array\n",
    "for i in range(catalog.shape[0]): # Cycles through each object in catalog\n",
    "    # Checks to make sure point is \"good\"\n",
    "    # Good defined by: 1. S/N > 5     2. Sharpness < .25     3. Roundness < 1     4. Crowding < .1 \n",
    "    #                  5. Object type = \"Bright Star\"     6. ML algorithm picks as good\n",
    "    if ((catalog[i][5] >= 10)&(abs(catalog[i][6]) < .25)&(abs(catalog[i][7]) < 1)\n",
    "        &(catalog[i][9] < .1)&(catalog[i][10] == 1)&(cat_predictions[i] == 'green')):\n",
    "        pos[j][0] = catalog[i][2] # Assigns X position with offset\n",
    "        pos[j][1] = catalog[i][3] # Assigns Y position with offset\n",
    "        allinfo[j] = catalog[i]\n",
    "        j = j + 1\n",
    "                \n",
    "# Trims all zeros from end of positions array, left from objects with low S/N\n",
    "pos = pos[~np.all(pos == 0, axis=1)]\n",
    "info = allinfo[~np.all(allinfo == 0, axis=1)]\n",
    "\n",
    "# Saves high S/N object X,Y positions\n",
    "np.savetxt(\"sn2010ae_ML2.reg\", pos, '%5.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5034, 271)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
